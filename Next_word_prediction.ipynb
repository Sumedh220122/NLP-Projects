{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKL3hzVvT0SNh1p8ooDj45"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"g_FZaX2BlgfP","executionInfo":{"status":"ok","timestamp":1718512195557,"user_tz":-330,"elapsed":1667,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"outputs":[],"source":["text = \"\"\"The quick brown fox jumps over the lazy dog.\n","This is a well-known sentence used for typing practice.\n","It contains every letter of the English alphabet,\n","which makes it a good example for demonstrating text processing techniques.\n","With enough training data, a model can learn to predict the next word in a sequence accurately.\n","Machine learning and natural language processing have advanced significantly, enabling the development of\n","sophisticated models that understand and generate human-like text. By feeding the LSTM model with this example text,\n","we can train it to predict the next word in a sequence. This is a useful exercise for understanding how recurrent neural networks\n","work and how they can be applied to language modeling tasks.\"\"\"\n"]},{"cell_type":"code","source":["text_list = text.split()\n","\n","modified_list = []\n","\n","for element in text_list:\n","  if element[-1] == \".\":\n","    element = element[0:-1]\n","  modified_list.append(element)\n","\n","print(modified_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXQzuXftZwu1","executionInfo":{"status":"ok","timestamp":1718512200941,"user_tz":-330,"elapsed":1065,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"e7eaf0f9-cedc-4554-d315-a7f26c5e20c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', 'This', 'is', 'a', 'well-known', 'sentence', 'used', 'for', 'typing', 'practice', 'It', 'contains', 'every', 'letter', 'of', 'the', 'English', 'alphabet,', 'which', 'makes', 'it', 'a', 'good', 'example', 'for', 'demonstrating', 'text', 'processing', 'techniques', 'With', 'enough', 'training', 'data,', 'a', 'model', 'can', 'learn', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'sequence', 'accurately', 'Machine', 'learning', 'and', 'natural', 'language', 'processing', 'have', 'advanced', 'significantly,', 'enabling', 'the', 'development', 'of', 'sophisticated', 'models', 'that', 'understand', 'and', 'generate', 'human-like', 'text', 'By', 'feeding', 'the', 'LSTM', 'model', 'with', 'this', 'example', 'text,', 'we', 'can', 'train', 'it', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'sequence', 'This', 'is', 'a', 'useful', 'exercise', 'for', 'understanding', 'how', 'recurrent', 'neural', 'networks', 'work', 'and', 'how', 'they', 'can', 'be', 'applied', 'to', 'language', 'modeling', 'tasks']\n"]}]},{"cell_type":"code","source":["set_chars = set(modified_list)"],"metadata":{"id":"2Hq8HOvrbRKL","executionInfo":{"status":"ok","timestamp":1718512206557,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(len(set_chars), len(modified_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIjedt4ZbU1T","executionInfo":{"status":"ok","timestamp":1718512211278,"user_tz":-330,"elapsed":529,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"364a7f46-04eb-4d90-c232-9da16596d1b9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["85 118\n"]}]},{"cell_type":"code","source":["vocab = sorted(set_chars)\n","\n","word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n","idx_to_word = {idx: word for idx, word in enumerate(vocab)}\n","\n","encode = lambda s: [word_to_idx[w] for w in s.split()]\n","decode = lambda l: ' '.join([idx_to_word[i] for i in l])"],"metadata":{"id":"SSkKBW7tn4aa","executionInfo":{"status":"ok","timestamp":1718512214478,"user_tz":-330,"elapsed":3,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["decode(encode(\"The quick brown fox\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"5It7ho3adQ9j","executionInfo":{"status":"ok","timestamp":1718512218338,"user_tz":-330,"elapsed":538,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"34727740-e99d-426b-8982-5b33da8adfb6"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The quick brown fox'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import torch\n","\n","text = text.replace('.', '')\n","\n","data = encode(text)"],"metadata":{"id":"fSfD3HH6n77X","executionInfo":{"status":"ok","timestamp":1718512232119,"user_tz":-330,"elapsed":4507,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["sequences = []\n","targets = []\n","\n","temp = 0\n","\n","sequence_length = 3\n","\n","for i in range(0, len(data) - sequence_length):\n","  temp = i\n","  sequences.append(data[i : i + sequence_length])\n","  targets.append(data[i + sequence_length])"],"metadata":{"id":"5h45nghpqlla","executionInfo":{"status":"ok","timestamp":1718512235205,"user_tz":-330,"elapsed":566,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","import torch.nn as nn\n","\n","class nextwordlstm(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers):\n","    super(nextwordlstm, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n","    self.fc = nn.Linear(hidden_dim, vocab_size)\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    out, _ = self.lstm(x)\n","    out = self.fc(out[:, -1])\n","    return out"],"metadata":{"id":"zTdhcA2plxfU","executionInfo":{"status":"ok","timestamp":1718512238120,"user_tz":-330,"elapsed":548,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(vocab)  # Size of the vocabulary\n","embedding_dim = 128      # Embedding dimensions for each word\n","hidden_dim = 256         # Hidden state dimensions\n","num_layers = 2           # Number of LSTM layers\n","\n","model = nextwordlstm(vocab_size, embedding_dim, hidden_dim, num_layers)\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1CHFcv4l6mG","executionInfo":{"status":"ok","timestamp":1718512240954,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"5d1a4936-9ce8-473d-d6bb-7fb827cd1a5a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["nextwordlstm(\n","  (embedding): Embedding(85, 128)\n","  (lstm): LSTM(128, 256, num_layers=2, batch_first=True)\n","  (fc): Linear(in_features=256, out_features=85, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"],"metadata":{"id":"ZYGyKw7Hr1Pm","executionInfo":{"status":"ok","timestamp":1718512246540,"user_tz":-330,"elapsed":1937,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["num_epochs = 20\n","batch_size = 3\n","\n","\n","for epoch in range(num_epochs):\n","    for i in range(0, len(sequences), batch_size):\n","        inputs = torch.Tensor(sequences[i:i + batch_size]).to(torch.int)\n","\n","        target_words = torch.Tensor(targets[i:i + batch_size]).to(torch.long)\n","\n","        outputs = model(inputs)\n","\n","        loss = criterion(outputs, target_words)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"],"metadata":{"id":"B7WNbCAmo6wd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718512261298,"user_tz":-330,"elapsed":12486,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"52514b08-e4e7-43fe-ac78-540de71fc592"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Loss: 4.7200\n","Epoch [2/20], Loss: 5.0361\n","Epoch [3/20], Loss: 3.8997\n","Epoch [4/20], Loss: 0.9962\n","Epoch [5/20], Loss: 0.0012\n","Epoch [6/20], Loss: 0.0027\n","Epoch [7/20], Loss: 0.0022\n","Epoch [8/20], Loss: 0.0017\n","Epoch [9/20], Loss: 0.0014\n","Epoch [10/20], Loss: 0.0011\n","Epoch [11/20], Loss: 0.0010\n","Epoch [12/20], Loss: 0.0008\n","Epoch [13/20], Loss: 0.0007\n","Epoch [14/20], Loss: 0.0007\n","Epoch [15/20], Loss: 0.0006\n","Epoch [16/20], Loss: 0.0005\n","Epoch [17/20], Loss: 0.0005\n","Epoch [18/20], Loss: 0.0004\n","Epoch [19/20], Loss: 0.0004\n","Epoch [20/20], Loss: 0.0004\n"]}]},{"cell_type":"code","source":["input_sequence = \"By feeding the\"\n","\n","\n","input_sequence = encode(input_sequence)\n","input_tensor = torch.Tensor(input_sequence).to(torch.int).unsqueeze(0)\n","\n","with torch.no_grad():\n","    outputs = model(input_tensor)\n","    probabilities = nn.functional.softmax(outputs, dim=1)\n","    predicted_index = torch.argmax(probabilities, dim=1).item()\n","\n","print(f'Predicted next word index: {predicted_index}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1lhCdqKqWSMA","executionInfo":{"status":"ok","timestamp":1718513165708,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"d13962f2-da27-4444-c8aa-23fef01e9136"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted next word index: 3\n"]}]},{"cell_type":"code","source":["input_sequence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"loKEhYwGeUMm","executionInfo":{"status":"ok","timestamp":1718513169398,"user_tz":-330,"elapsed":528,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"5332748e-3f68-485b-b2e7-dcca3c12c7b7"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 27, 68]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["print(decode([0, 27, 68, 3]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"Hq5M9QyMeReC","executionInfo":{"status":"error","timestamp":1718513066971,"user_tz":-330,"elapsed":567,"user":{"displayName":"Sumedh R","userId":"05948546022201142515"}},"outputId":"c485afde-2c2a-480a-c8e2-9756589c6f57"},"execution_count":31,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"'NoneType' object is not iterable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-f4295de3768c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-a54779e2d00a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"]}]}]}